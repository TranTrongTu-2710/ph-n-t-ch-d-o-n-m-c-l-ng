"""
·ª®ng d·ª•ng Web d·ª± ƒëo√°n l∆∞∆°ng (Streamlit + PySpark).

M·ª§C TI√äU:
- T·∫°o giao di·ªán ng∆∞·ªùi d√πng th√¢n thi·ªán.
- Load Pipeline v√† Model ƒë√£ hu·∫•n luy·ªán t·ª´ Spark.
- Nh·∫≠n input t·ª´ ng∆∞·ªùi d√πng -> Bi·∫øn ƒë·ªïi qua Pipeline -> D·ª± ƒëo√°n b·∫±ng Model -> Hi·ªÉn th·ªã k·∫øt qu·∫£.
"""

import streamlit as st
import os
import numpy as np
import pandas as pd
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
from pyspark.ml.regression import GBTRegressionModel

# ===== C·∫§U H√åNH =====
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "models")
PIPELINE_PATH = os.path.join(MODEL_DIR, "feature_pipeline_model")
GBT_MODEL_PATH = os.path.join(MODEL_DIR, "gbt_model")

# ===== KH·ªûI T·∫†O SPARK =====
@st.cache_resource # Cache ƒë·ªÉ kh√¥ng ph·∫£i kh·ªüi ƒë·ªông l·∫°i Spark m·ªói l·∫ßn reload trang
def get_spark():
    """Kh·ªüi t·∫°o SparkSession ch·∫°y ng·∫ßm b√™n d∆∞·ªõi Web App"""
    spark = (
        SparkSession.builder
        .appName("Salary_Prediction_WebApp")
        .master("local[*]") # Ch·∫°y local
        .config("spark.driver.memory", "2g") # C·∫•p 2GB RAM cho driver
        .getOrCreate()
    )
    spark.sparkContext.setLogLevel("ERROR")
    return spark

# ===== LOAD MODELS =====
@st.cache_resource
def load_models(_spark):
    """Load Pipeline x·ª≠ l√Ω d·ªØ li·ªáu v√† Model d·ª± ƒëo√°n ƒë√£ l∆∞u tr∆∞·ªõc ƒë√≥"""
    if not os.path.exists(PIPELINE_PATH) or not os.path.exists(GBT_MODEL_PATH):
        return None, None
    
    # PipelineModel: Ch·ª©a logic bi·∫øn ƒë·ªïi text -> vector
    pipeline_model = PipelineModel.load(PIPELINE_PATH)
    # GBTRegressionModel: Ch·ª©a logic d·ª± ƒëo√°n l∆∞∆°ng t·ª´ vector
    gbt_model = GBTRegressionModel.load(GBT_MODEL_PATH)
    return pipeline_model, gbt_model

# ===== GIAO DI·ªÜN (UI) =====
st.set_page_config(page_title="Salary Predictor", page_icon="üí∞")

st.title("üí∞ IT Salary Prediction")
st.markdown("D·ª± ƒëo√°n m·ª©c l∆∞∆°ng l·∫≠p tr√¨nh vi√™n d·ª±a tr√™n d·ªØ li·ªáu StackOverflow Survey.")

spark = get_spark()
pipeline_model, gbt_model = load_models(spark)

if not pipeline_model or not gbt_model:
    st.error("‚ùå Kh√¥ng t√¨m th·∫•y Model! H√£y ch·∫°y step_3 v√† train_regression_v2 tr∆∞·ªõc.")
    st.stop()

# --- FORM NH·∫¨P LI·ªÜU ---
with st.form("predict_form"):
    col1, col2 = st.columns(2)
    
    with col1:
        years_pro = st.number_input("Years of Professional Experience", min_value=0.0, max_value=50.0, value=3.0, step=0.5)
        country = st.selectbox("Country", ["United States of America", "Germany", "United Kingdom", "India", "Canada", "France", "Brazil", "Poland", "Netherlands", "Australia", "Other"])
        ed_level = st.selectbox("Education Level", [
            "Bachelor‚Äôs degree (B.A., B.S., B.Eng., etc.)",
            "Master‚Äôs degree (M.A., M.S., M.Eng., MBA, etc.)",
            "Some college/university study without earning a degree",
            "Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)",
            "Other doctoral degree (Ph.D., Ed.D., etc.)",
            "Professional degree (JD, MD, etc.)"
        ])

    with col2:
        remote = st.selectbox("Remote Work", ["Remote", "Hybrid (some remote, some in-person)", "In-person"])
        org_size = st.selectbox("Organization Size", [
            "20 to 99 employees", "100 to 499 employees", "10,000 or more employees",
            "1,000 to 4,999 employees", "2 to 9 employees", "10 to 19 employees",
            "500 to 999 employees", "5,000 to 9,999 employees", "Just me - I am a freelancer, sole proprietor, etc."
        ])
        
        # Ch·ªçn k·ªπ nƒÉng (Demo m·ªôt s·ªë ph·ªï bi·∫øn)
        languages = st.multiselect("Languages Worked With", 
            ["Python", "JavaScript", "Java", "C#", "C++", "TypeScript", "SQL", "HTML/CSS", "Bash/Shell", "Go", "Rust", "PHP"])
        databases = st.multiselect("Databases Worked With", 
            ["PostgreSQL", "MySQL", "SQLite", "MongoDB", "Redis", "Microsoft SQL Server", "MariaDB", "Elasticsearch", "Oracle"])

    submitted = st.form_submit_button("üöÄ Predict Salary")

# --- LOGIC D·ª∞ ƒêO√ÅN ---
if submitted:
    # 1. T·∫°o DataFrame t·ª´ input ng∆∞·ªùi d√πng
    input_data = [{
        "YearsCodeProNum_imp": float(years_pro), # D√πng t√™n c·ªôt kh·ªõp v·ªõi l√∫c train
        "CountryGrouped": country,
        "EdLevel": ed_level,
        "RemoteWork": remote,
        "OrgSize": org_size,
        "LanguageHaveWorkedWith": ";".join(languages), # N·ªëi l·∫°i th√†nh chu·ªói ngƒÉn c√°ch b·ªüi ;
        "DatabaseHaveWorkedWith": ";".join(databases)
    }]
    
    input_df = spark.createDataFrame(input_data)
    
    # 2. Transform qua pipeline (Bi·∫øn ƒë·ªïi text -> vector)
    try:
        features_df = pipeline_model.transform(input_df)
        
        # 3. Predict (D·ª± ƒëo√°n log l∆∞∆°ng)
        prediction = gbt_model.transform(features_df)
        pred_log = prediction.select("prediction").collect()[0][0]
        
        # 4. Convert log -> real (ƒê·ªïi v·ªÅ l∆∞∆°ng th·∫≠t)
        salary_pred = np.expm1(pred_log)
        
        st.success(f"### üíµ Predicted Annual Salary: ${salary_pred:,.2f}")
        st.info(f"Log Value: {pred_log:.4f}")
        
    except Exception as e:
        st.error(f"Error during prediction: {e}")
